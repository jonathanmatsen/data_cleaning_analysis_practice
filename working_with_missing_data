import pandas as pd
mvc = pd.read_csv("nypd_mvc_2018.csv")

null_counts = mvc.isnull().sum()

#verifying column totals
killed_cols = [col for col in mvc.columns if 'killed' in col]
killed = mvc[killed_cols].copy()

killed_manual_sum = killed[['pedestrians_killed', 'cyclist_killed', 'motorist_killed']].sum(axis=1)

killed_mask = killed_manual_sum != killed['total_killed']

killed_non_eq = killed[killed_mask]

# Create an injured dataframe and manually sum values
injured = mvc[[col for col in mvc.columns if 'injured' in col]].copy()
injured_manual_sum = injured.iloc[:,:3].sum(axis=1)

injured['total_injured'] = injured['total_injured'].mask(injured['total_injured'].isnull(), injured_manual_sum)

injured['total_injured'] = injured['total_injured'].mask(injured['total_injured'] != injured_manual_sum, np.nan)

#assign correctd data back to original dataframe

mvc['total_injured'] = injured['total_injured']

mvc['total_killed'] = killed['total_killed']

#visualize missing data with plots

import matplotlib.pyplot as plt
import seaborn as sns

def plot_null_correlations(df):
    # create a correlation matrix only for columns with at least
    # one missing value
    cols_with_missing_vals = df.columns[df.isnull().sum() > 0]
    missing_corr = df[cols_with_missing_vals].isnull().corr()

    # create a triangular mask to avoid repeated values and make
    # the plot easier to read
    missing_corr = missing_corr.iloc[1:, :-1]
    mask = np.triu(np.ones_like(missing_corr), k=1)

    # plot a heatmap of the values
    plt.figure(figsize=(20,14))
    ax = sns.heatmap(missing_corr, vmin=-1, vmax=1, cbar=False,
                     cmap='RdBu', mask=mask, annot=True)

    # format the text in the plot to make it easier to read
    for text in ax.texts:
        t = float(text.get_text())
        if -0.05 < t < 0.01:
            text.set_text('')
        else:
            text.set_text(round(t, 2))
        text.set_fontsize('x-large')
    plt.xticks(rotation=90, size='x-large')
    plt.yticks(rotation=0, size='x-large')

    plt.show()

veh_cols = [col for col in mvc if 'vehicle' in col]

plot_null_correlations(mvc[veh_cols])

#analyzing correlations in missing data

col_labels = ['v_number', 'vehicle_missing', 'cause_missing']

vc_null_data = []

for v in range(1,6):
    v_col = 'vehicle_{}'.format(v)
    c_col = 'cause_vehicle_{}'.format(v)

    v_null = (mvc[v_col].isnull() & mvc[c_col].notnull()).sum()
    c_null = (mvc[c_col].isnull() & mvc[v_col].notnull()).sum()

    vc_null_data.append([v, v_null, c_null])

vc_null_df = pd.DataFrame(data=vc_null_data, columns=col_labels)

#finding the most common values across multiple columns

v_cols = [c for c in mvc.columns if c.startswith("vehicle")]

vehicles = mvc[v_cols]

vehicles_1d = vehicles.stack()

top10_vehicles = vehicles_1d.value_counts().head(10)
